{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem- C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\91755\\Downloads\\concrete_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>47.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>43.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "5   266.0               114.0      0.0  228.0               0.0   \n",
       "6   380.0                95.0      0.0  228.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  \n",
       "5             932.0           670.0   90     47.03  \n",
       "6             932.0           594.0  365     43.70  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
    "       'Coarse Aggregate', 'Fine Aggregate', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=((x-x.mean())/x.std())\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential as seq\n",
    "from keras.layers import Flatten,Dense,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import mean_squared_error as mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=seq()   #creating model object\n",
    "model.add(Dense(10,activation='relu',input_shape=(8,)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])  #compiling the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=tts(x,y,test_size=0.3,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "721/721 [==============================] - 0s 120us/step - loss: 1581.8413 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "721/721 [==============================] - 0s 36us/step - loss: 1566.9601 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 1552.4613 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "721/721 [==============================] - 0s 39us/step - loss: 1538.0893 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "721/721 [==============================] - 0s 40us/step - loss: 1523.5119 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "721/721 [==============================] - 0s 47us/step - loss: 1508.4464 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "721/721 [==============================] - 0s 40us/step - loss: 1492.6119 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "721/721 [==============================] - 0s 44us/step - loss: 1476.1992 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "721/721 [==============================] - 0s 47us/step - loss: 1458.8017 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 1439.6631 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "721/721 [==============================] - 0s 35us/step - loss: 1419.9518 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "721/721 [==============================] - 0s 40us/step - loss: 1398.0687 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 1374.9359 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "721/721 [==============================] - 0s 39us/step - loss: 1350.3878 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 1323.9490 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "721/721 [==============================] - 0s 36us/step - loss: 1296.2167 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 1266.8490 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1236.0747 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 1204.0682 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 1170.6376 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "721/721 [==============================] - 0s 35us/step - loss: 1136.0370 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "721/721 [==============================] - 0s 37us/step - loss: 1100.7713 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 1064.0480 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 1027.1566 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "721/721 [==============================] - 0s 41us/step - loss: 989.6667 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 952.1347 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 913.3609 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 875.3644 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 836.7908 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "721/721 [==============================] - 0s 35us/step - loss: 798.8607 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 760.4254 - accuracy: 0.0014\n",
      "Epoch 32/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 722.7970 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "721/721 [==============================] - 0s 36us/step - loss: 685.8629 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "721/721 [==============================] - 0s 39us/step - loss: 649.1191 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "721/721 [==============================] - 0s 41us/step - loss: 614.1817 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "721/721 [==============================] - 0s 39us/step - loss: 580.2982 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "721/721 [==============================] - 0s 30us/step - loss: 548.0983 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 517.8530 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "721/721 [==============================] - 0s 37us/step - loss: 488.8706 - accuracy: 0.0014\n",
      "Epoch 40/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 461.1693 - accuracy: 0.0014\n",
      "Epoch 41/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 435.8660 - accuracy: 0.0028\n",
      "Epoch 42/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 411.9883 - accuracy: 0.0014\n",
      "Epoch 43/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 389.7584 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "721/721 [==============================] - 0s 37us/step - loss: 369.4513 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 350.6525 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 333.0379 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "721/721 [==============================] - 0s 35us/step - loss: 317.2459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "721/721 [==============================] - 0s 40us/step - loss: 302.9865 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "721/721 [==============================] - 0s 43us/step - loss: 290.0399 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "721/721 [==============================] - 0s 39us/step - loss: 278.3528 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "721/721 [==============================] - 0s 36us/step - loss: 267.7769 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "721/721 [==============================] - 0s 30us/step - loss: 258.5134 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "721/721 [==============================] - 0s 37us/step - loss: 250.0374 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "721/721 [==============================] - 0s 30us/step - loss: 242.5659 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "721/721 [==============================] - 0s 36us/step - loss: 235.7164 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 229.8284 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "721/721 [==============================] - 0s 36us/step - loss: 224.1482 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "721/721 [==============================] - 0s 30us/step - loss: 219.2248 - accuracy: 0.0014\n",
      "Epoch 59/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 214.7962 - accuracy: 0.0028\n",
      "Epoch 60/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 210.7461 - accuracy: 0.0028\n",
      "Epoch 61/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 206.9867 - accuracy: 0.0028\n",
      "Epoch 62/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 203.6803 - accuracy: 0.0042\n",
      "Epoch 63/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 200.6231 - accuracy: 0.0014\n",
      "Epoch 64/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 197.7650 - accuracy: 0.0014\n",
      "Epoch 65/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 195.3653 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 192.9056 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 190.8242 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 188.6481 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 186.7820 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 184.8760 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 183.1737 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 181.5483 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "721/721 [==============================] - 0s 62us/step - loss: 179.9688 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 178.4262 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 177.0124 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 175.4904 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 174.2460 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 172.9105 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 171.6292 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 170.4870 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 169.3471 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 168.2575 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 167.2424 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 166.2127 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 165.2238 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 164.3186 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 163.3001 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 162.3386 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 161.4289 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 160.6055 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 159.6957 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 158.8165 - accuracy: 0.0014\n",
      "Epoch 93/100\n",
      "721/721 [==============================] - 0s 43us/step - loss: 158.0436 - accuracy: 0.0014\n",
      "Epoch 94/100\n",
      "721/721 [==============================] - 0s 51us/step - loss: 157.1330 - accuracy: 0.0014\n",
      "Epoch 95/100\n",
      "721/721 [==============================] - 0s 43us/step - loss: 156.3290 - accuracy: 0.0014\n",
      "Epoch 96/100\n",
      "721/721 [==============================] - 0s 48us/step - loss: 155.4757 - accuracy: 0.0014\n",
      "Epoch 97/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 154.6064 - accuracy: 0.0014\n",
      "Epoch 98/100\n",
      "721/721 [==============================] - 0s 21us/step - loss: 153.8595 - accuracy: 0.0014\n",
      "Epoch 99/100\n",
      "721/721 [==============================] - 0s 18us/step - loss: 153.0148 - accuracy: 0.0014\n",
      "Epoch 100/100\n",
      "721/721 [==============================] - 0s 21us/step - loss: 152.1647 - accuracy: 0.0014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2c14b09f788>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 48us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[167.61729757068227, 0.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "model.evaluate(x_test,y_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167.61728992231593\n"
     ]
    }
   ],
   "source": [
    "mse1=mse(y_test,y_pred)\n",
    "print(mse1)\n",
    "# mean squared error \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 1: [91.09231098261466, 0.0]\n",
      "MSE 2: [78.23436517314232, 0.0032362460624426603]\n",
      "MSE 3: [48.36076526580119, 0.0]\n",
      "MSE 4: [43.06460281174545, 0.0]\n",
      "MSE 5: [42.61331205151999, 0.0]\n",
      "MSE 6: [43.453412287443584, 0.0]\n",
      "MSE 7: [45.36891087899316, 0.0]\n",
      "MSE 8: [33.52437959442633, 0.0]\n",
      "MSE 9: [36.53694662692863, 0.0]\n",
      "MSE 10: [36.85292364324181, 0.0]\n",
      "MSE 11: [39.25075227311514, 0.0]\n",
      "MSE 12: [33.403401155687845, 0.0]\n",
      "MSE 13: [41.20302817582313, 0.0]\n",
      "MSE 14: [43.97571583473181, 0.0]\n",
      "MSE 15: [36.049732874898076, 0.0]\n",
      "MSE 16: [32.20468443960048, 0.0]\n",
      "MSE 17: [35.930081500204636, 0.0]\n",
      "MSE 18: [35.15950730086144, 0.0]\n",
      "MSE 19: [35.231525211272505, 0.0]\n",
      "MSE 20: [39.300880333366514, 0.0]\n",
      "MSE 21: [34.42176420094512, 0.0]\n",
      "MSE 22: [34.46525566940554, 0.0]\n",
      "MSE 23: [29.95253264788285, 0.0]\n",
      "MSE 24: [36.34733202542302, 0.0]\n",
      "MSE 25: [35.6888766057283, 0.0]\n",
      "MSE 26: [38.048427865728975, 0.0]\n",
      "MSE 27: [32.27978831664644, 0.0]\n",
      "MSE 28: [32.072185022545476, 0.0]\n",
      "MSE 29: [39.717910198717824, 0.0]\n",
      "MSE 30: [37.87033769922349, 0.0]\n",
      "MSE 31: [34.29897605871305, 0.0]\n",
      "MSE 32: [33.34705544752596, 0.0]\n",
      "MSE 33: [34.37917732806653, 0.0]\n",
      "MSE 34: [35.97939591886156, 0.0]\n",
      "MSE 35: [37.14987943087581, 0.0]\n",
      "MSE 36: [40.82841267014784, 0.0]\n",
      "MSE 37: [32.49727966407356, 0.0]\n",
      "MSE 38: [38.168109239498, 0.0]\n",
      "MSE 39: [33.99764540588971, 0.0]\n",
      "MSE 40: [29.80521554545677, 0.0]\n",
      "MSE 41: [38.38735300206058, 0.0]\n",
      "MSE 42: [30.218516784964255, 0.0]\n",
      "MSE 43: [36.056080586701924, 0.0]\n",
      "MSE 44: [39.646151866727664, 0.0]\n",
      "MSE 45: [38.04218161376163, 0.0]\n",
      "MSE 46: [40.2518249067288, 0.0]\n",
      "MSE 47: [34.2552270981872, 0.0]\n",
      "MSE 48: [37.103172808403336, 0.0]\n",
      "MSE 49: [36.7740074577455, 0.0]\n",
      "MSE 50: [40.24888779970434, 0.0]\n",
      "MSE 51: [31.59184789811909, 0.0]\n",
      "MSE 52: [33.31400363576451, 0.0032362460624426603]\n",
      "MSE 53: [34.76008930638384, 0.0]\n",
      "MSE 54: [32.25221164789786, 0.0]\n",
      "MSE 55: [41.94058136801118, 0.0]\n",
      "MSE 56: [32.85082507827907, 0.0]\n",
      "MSE 57: [33.31035825118278, 0.0]\n",
      "MSE 58: [34.533638988112166, 0.0]\n",
      "MSE 59: [39.87985579481403, 0.0]\n",
      "MSE 60: [36.56947885902183, 0.0]\n",
      "MSE 61: [37.14389771396674, 0.0]\n",
      "MSE 62: [30.266122015548756, 0.0]\n",
      "MSE 63: [34.93548919159232, 0.0032362460624426603]\n",
      "MSE 64: [36.27006573970264, 0.0]\n",
      "MSE 65: [34.83144803340381, 0.0032362460624426603]\n",
      "MSE 66: [36.61663101097527, 0.0]\n",
      "MSE 67: [35.24766371396753, 0.0]\n",
      "MSE 68: [37.63979291452945, 0.0]\n",
      "MSE 69: [31.921615816628663, 0.0]\n",
      "MSE 70: [34.21529476079355, 0.0]\n",
      "MSE 71: [35.99290373718854, 0.0]\n",
      "MSE 72: [34.0082893371582, 0.0032362460624426603]\n",
      "MSE 73: [31.5291299912536, 0.0]\n",
      "MSE 74: [33.15826538234081, 0.0]\n",
      "MSE 75: [34.08195711030929, 0.0]\n",
      "MSE 76: [34.5956231891916, 0.0]\n",
      "MSE 77: [31.131480232411604, 0.0]\n",
      "MSE 78: [30.48436188929289, 0.0]\n",
      "MSE 79: [39.38288540516085, 0.0]\n",
      "MSE 80: [36.315337677989575, 0.0]\n",
      "MSE 81: [32.57143097170734, 0.0]\n",
      "MSE 82: [35.0820663970651, 0.0]\n",
      "MSE 83: [34.101793060796545, 0.0032362460624426603]\n",
      "MSE 84: [34.94166756293534, 0.0]\n",
      "MSE 85: [30.64920119251634, 0.0]\n",
      "MSE 86: [31.39965951172665, 0.0]\n",
      "MSE 87: [35.2514138700121, 0.0032362460624426603]\n",
      "MSE 88: [31.071196719666514, 0.0]\n",
      "MSE 89: [32.09542189909802, 0.0]\n",
      "MSE 90: [29.46019268344521, 0.0]\n",
      "MSE 91: [37.3889204352419, 0.0]\n",
      "MSE 92: [27.941838983578975, 0.0]\n",
      "MSE 93: [35.65998867491688, 0.0]\n",
      "MSE 94: [31.655245771685852, 0.0]\n",
      "MSE 95: [36.28623141439987, 0.0032362460624426603]\n",
      "MSE 96: [31.168515850425152, 0.0]\n",
      "MSE 97: [37.37136177877778, 0.0]\n",
      "MSE 98: [31.840672934325383, 0.0]\n",
      "MSE 99: [35.68925412495931, 0.0]\n",
      "MSE 100: [34.90900833475551, 0.0]\n"
     ]
    }
   ],
   "source": [
    "mse_l=[]\n",
    "for i in range(0,100):\n",
    "    x_train,x_test,y_train,y_test=tts(x,y,test_size=0.3,random_state=i)\n",
    "    model.fit(x_train,y_train,epochs=100,verbose=0)\n",
    "    MSE=model.evaluate(x_test,y_test,verbose=0)\n",
    "    print(\"MSE \"+str(i+1)+\": \"+str(MSE))\n",
    "    y_pred=model.predict(x_test)\n",
    "    mse_=mse(y_test,y_pred)\n",
    "    mse_l.append(mse_)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.90900877315474 \n",
      " \n",
      " 0.0\n"
     ]
    }
   ],
   "source": [
    "mse_l = np.array(mse_)\n",
    "mean = np.mean(mse_l)\n",
    "standard_deviation = np.std(mse_l)\n",
    "print(mean,'\\n','\\n', standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the error is less, in compared to problem-A but slightly greater as compared to problem -B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
